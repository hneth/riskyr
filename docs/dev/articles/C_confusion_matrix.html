<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Confusion Matrix and Metrics • riskyr</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Confusion Matrix and Metrics">
<meta property="og:description" content="">
<meta property="og:image" content="https://hneth.github.io/riskyr/logo.png">
<meta name="twitter:card" content="summary">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">riskyr</a>
        <span class="version label label-danger" data-toggle="tooltip" data-placement="bottom" title="In-development version">0.2.0.9008</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="../articles/E_riskyr_primer.html">Getting started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    All articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/A_user_guide.html">User guide</a>
    </li>
    <li>
      <a href="../articles/B_data_formats.html">Data formats</a>
    </li>
    <li>
      <a href="../articles/C_confusion_matrix.html">Confusion matrix</a>
    </li>
    <li>
      <a href="../articles/D_functional_perspectives.html">Functional perspectives</a>
    </li>
    <li>
      <a href="../articles/E_riskyr_primer.html">Quick start primer</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://hneth.github.io/riskyr/">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Confusion Matrix and Metrics</h1>
                        <h4 class="author">Hansjörg Neth, SPDS, uni.kn</h4>
            
            <h4 class="date">2018 02 12</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/hneth/riskyr/blob/master/vignettes/C_confusion_matrix.Rmd"><code>vignettes/C_confusion_matrix.Rmd</code></a></small>
      <div class="hidden name"><code>C_confusion_matrix.Rmd</code></div>

    </div>

    
    
<p>Behold the aptly named “confusion matrix”:</p>
<table class="table">
<colgroup>
<col width="16%">
<col width="15%">
<col width="15%">
<col width="15%">
<col width="15%">
</colgroup>
<thead><tr class="header">
<th align="right"></th>
<th align="center">Condition</th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Decision</strong></td>
<td align="center">present (<code>TRUE</code>):</td>
<td align="center">absent (<code>FALSE</code>):</td>
<td align="center">Sum:</td>
<td align="center">(b) by decision:</td>
</tr>
<tr class="even">
<td align="right">positive (<code>TRUE</code>):</td>
<td align="center"><code>hi</code></td>
<td align="center"><code>fa</code></td>
<td align="center"><code>dec_pos</code></td>
<td align="center">
<code>PPV</code> = <code>hi</code>/<code>dec_pos</code>
</td>
</tr>
<tr class="odd">
<td align="right">negative (<code>FALSE</code>):</td>
<td align="center"><code>mi</code></td>
<td align="center"><code>cr</code></td>
<td align="center"><code>dec_neg</code></td>
<td align="center">
<code>NPV</code> = <code>cr</code>/<code>dec_neg</code>
</td>
</tr>
<tr class="even">
<td align="right">Sum:</td>
<td align="center"><code>cond_true</code></td>
<td align="center"><code>cond_false</code></td>
<td align="center"><code>N</code></td>
<td align="center">
<code>prev</code> = <code>cond_true</code>/<code>N</code>
</td>
</tr>
<tr class="odd">
<td align="right">(a) by condition</td>
<td align="center">
<code>sens</code> = <code>hi</code>/<code>cond_true</code>
</td>
<td align="center">
<code>spec</code> = <code>cr</code>/<code>cond_false</code>
</td>
<td align="center">
<code>ppod</code> = <code>dec_pos</code>/<code>N</code>
</td>
<td align="center">
<code>acc</code> = <code>dec_cor</code>/<code>N</code> = (<code>hi</code>+<code>cr</code>)/<code>N</code>
</td>
</tr>
</tbody>
</table>
<p>Most people, including medical experts and social scientists, struggle to understand the implications of this matrix. This is no surprise when considering explanations like the corresponding article on <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Wikipedia</a>, which squeezes more than a dozen metrics out of four essential frequencies (<code>hi</code>, <code>mi</code>, <code>fa</code>, and <code>cr</code>). While each particular metric is quite simple, their abundance and inter-dependence can be overwhelming.</p>
<p>Fortunately, the basic matrix can also be understood as a 2-by-2 contingency table, which is actually quite simple, and rather straightforward in its implications. In the following, we aim to disentangle the multitude of measures and identify the elements of the confusion matrix that a risk-literate person should know.</p>
<!-- 

## Terminology

|              | 'cols' |          |       |          |            
| ----------:  |:--------:|:--------:|:--------:|:--------:|              
| `rows` | left (`TRUE`):      | right (`FALSE`):     |     Sum:  |  (b) by decision: |  
| top (`TRUE`):   | `tl`         | `tr`         | `t` | `ptl` = `tl`/`t`  `ptr` = `tr`/`t` |
| bottom (`FALSE`):  | `bl`       | `br`      | `b` | `NPV` = `cr`/`dec_neg` |
|      Sum:    | `l`  | `r` |       `N` |         `pl` =  `nl`/`N`     |
| (a) by condition  | `ptl` = `tl`/`l` `pbl` = `bl`/`l`   | `spec` = `cr`/`cond_false` | `pt` = `nt`/`N` |  `acc` = `dec_cor`/`N` = (`hi`+`cr`)/`N` |

-->
<div id="basics" class="section level2">
<h2 class="hasAnchor">
<a href="#basics" class="anchor"></a>Basics</h2>
<p>Condensed to its core, the confusion matrix cross-tabulates two binary dimensions and classifies each individual case into one of 4 possible categories that result from combining the two binary variables (e.g., the condition and decision of each case) with each other. This may still sound complicated, but looks like this:</p>
<table class="table">
<thead><tr class="header">
<th align="right"></th>
<th align="center">Condition</th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Decision</strong></td>
<td align="center">present (<code>TRUE</code>):</td>
<td align="center">absent (<code>FALSE</code>):</td>
</tr>
<tr class="even">
<td align="right">positive (<code>TRUE</code>):</td>
<td align="center"><code>hi</code></td>
<td align="center"><code>fa</code></td>
</tr>
<tr class="odd">
<td align="right">negative (<code>FALSE</code>):</td>
<td align="center"><code>mi</code></td>
<td align="center"><code>cr</code></td>
</tr>
</tbody>
</table>
<p>Fortunately, this is not so confusing any more. And, perhaps surprisingly, all other metrics follow from this simple core in a straightforward way. In the following, we illustrate how the other metrics can be constructed from the 4 essential frequencies in the core of the matrix.</p>
<div id="adopting-2-perspectives-on-a-population" class="section level3">
<h3 class="hasAnchor">
<a href="#adopting-2-perspectives-on-a-population" class="anchor"></a>Adopting 2 perspectives on a population</h3>
<p>Essentially, the confusion matrix views a population of <code>N</code> individuals in different ways by adopting different perspectives. “Adopting a perspective” means that we can distinguish between individuals on the basis of some criterion. The 2 primary criteria used here are:</p>
<ol style="list-style-type: lower-alpha">
<li>each individual’s <em>condition</em>, which can either be present (<code>TRUE</code>) or absent (<code>FALSE</code>), and<br>
</li>
<li>each individual’s <em>decision</em>, which can either be <code>positive</code> (<code>TRUE</code>) or <code>negative</code> (<code>FALSE</code>).</li>
</ol>
<p>Numerically, the adoption of each of these two perspectives splits the population into two subgroups.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Applying two different splits of a population into two subgroups results in <span class="math inline">\(2 \times 2 = 4\)</span> cases, which form the core of the confusion matrix:</p>
<ol style="list-style-type: decimal">
<li>
<code>hi</code> represents <em>hits</em> (or true positives): condition present (<code>TRUE</code>) &amp; decision positive (<code>TRUE</code>).</li>
<li>
<code>mi</code> represents <em>misses</em> (or false negatives): condition present (<code>TRUE</code>) &amp; decision negative (<code>FALSE</code>).</li>
<li>
<code>fa</code> represents <em>false alarms</em> (or false positives): condition absent (<code>FALSE</code>) &amp; decision positive (<code>TRUE</code>).</li>
<li>
<code>cr</code> represents <em>correct rejections</em> (or true negatives): condition absent (<code>FALSE</code>) &amp; decision negative (<code>FALSE</code>).</li>
</ol>
<p>Importantly, all frequencies required to understand and compute various metrics are combinations of these four frequencies — which is why we refer to them as the four <em>essential</em> frequencies (see the vignette on <a href="B_data_formats.html">Data formats</a>). For instance, adding up the columns and rows of the matrix yields the frequencies of the two subgroups that result from adopting our two perspectives on the population <code>N</code> (or splitting <code>N</code> into subgroups by applying two binary criteria):</p>
<ol style="list-style-type: lower-alpha">
<li>by condition (corresponding to the two columns of the confusion matrix):</li>
</ol>
<p><span class="math display">\[ 
\begin{aligned}
\texttt{N} \ &amp;= \ \texttt{cond_true} &amp; +\ \ \ \ \ &amp;\texttt{cond_false}   &amp; \textrm{(a)}      \\
           \ &amp;= \ (\texttt{hi} + \texttt{mi}) &amp; +\ \ \ \ \ &amp;(\texttt{fa} + \texttt{cr}) \\
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>by decision (corresponding to the two rows of the confusion matrix):</li>
</ol>
<p><span class="math display">\[ 
\begin{aligned}
\texttt{N} \ &amp;= \ \texttt{dec_pos} &amp; +\ \ \ \ \ &amp;\texttt{dec_neg}   &amp; \ \ \ \ \textrm{(b)}      \\
           \ &amp;= \ (\texttt{hi} + \texttt{fa}) &amp; +\ \ \ \ \ &amp;(\texttt{mi} + \texttt{cr})         \\
\end{aligned}
\]</span></p>
<p>To reflect these two perspectives in the confusion matrix, we only need to add the sums of columns (i.e., by condition) and rows (by decision):</p>
<table class="table">
<thead><tr class="header">
<th align="right"></th>
<th align="center">Condition</th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Decision</strong></td>
<td align="center">present (<code>TRUE</code>):</td>
<td align="center">absent (<code>FALSE</code>):</td>
<td align="center">Sum:</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right">positive (<code>TRUE</code>):</td>
<td align="center"><code>hi</code></td>
<td align="center"><code>fa</code></td>
<td align="center"><code>dec_pos</code></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="right">negative (<code>FALSE</code>):</td>
<td align="center"><code>mi</code></td>
<td align="center"><code>cr</code></td>
<td align="center"><code>dec_neg</code></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right">Sum:</td>
<td align="center"><code>cond_true</code></td>
<td align="center"><code>cond_false</code></td>
<td align="center"><code>N</code></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<div id="example" class="section level4">
<h4 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h4>
<p>To view a 2x2 confusion table in <code>riskyr</code>, use the <code>plot_tab</code> function or plot an existing scenario as <code>type = "tab"</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## (1) Plot table from basic input parameters: ----- 
<span class="kw"><a href="../reference/plot_tab.html">plot_tab</a></span>(<span class="dt">prev =</span> .<span class="dv">05</span>, <span class="dt">sens =</span> .<span class="dv">75</span>, <span class="dt">spec =</span> .<span class="dv">66</span>, <span class="dt">N =</span> <span class="dv">1000</span>,
         <span class="dt">p_lbl =</span> <span class="st">"def"</span>) <span class="co"># show condition probabilies (by default)</span>

## Alternative version (with horizontal p):
<span class="co"># plot_tab(prev = .05, sens = .75, spec = .66, N = 1000,</span>
<span class="co">#          p_lbl = "def", p_split = "h") # show decision probabilities</span>

## (2) Plot an existing riskyr scenario: ----- 
<span class="co"># s1 &lt;- scenarios$n1  # identify s1 from scenarios</span>
<span class="co"># plot(s1, type = "tab", p_lbl = "def")</span></code></pre></div>
<div class="figure">
<img src="C_confusion_matrix_files/figure-html/plot_tab_demo-1.png" alt="Example of a 2x2 confusion table in `riskyr`." width="672"><p class="caption">
Example of a 2x2 confusion table in <code>riskyr</code>.
</p>
</div>
<!-- (The plots are not shown here, but please go ahead and generate them for yourself.) -->
<!-- 

#### ToDo

- Provide a numeric example.

- Show corresponding table, mosaic plot, and/or prism plot/network diagram. 

- Distinguish between different scenario types and causal models: 
    - detection (e.g., in clinical diagnostics), 
    - treatment (e.g., RCTs), 
    - prevention (e.g., vaccination). 

-->
</div>
</div>
<div id="accuracy-as-a-3rd-perspective" class="section level3">
<h3 class="hasAnchor">
<a href="#accuracy-as-a-3rd-perspective" class="anchor"></a>Accuracy as a 3rd perspective</h3>
<p>A 3rd way of grouping the four essential frequencies results from asking the question: Which of the four essential frequencies are <em>correct</em> decisions and which are <em>erroneous</em> decisions? Crucially, this question about decision <em>accuracy</em> can neither be answered by only considering each individual’s condition (i.e., the columns of the matrix), nor can it be answered by only considering each individual’s decision (i.e., the rows of the matrix). Instead, answering the question about accuracy requires that the other dimensions have been determined and then considering the <em>correspondence</em> between condition and decision. Checking the correspondence between rows and columns for the four essential frequencies yields an important insight: The confusion matrix contains <em>two</em> types of correct decisions and <em>two</em> types of errors:</p>
<ul>
<li>
<p>A decision is <em>correct</em>, when it corresponds to the condition. This is the case for two cells in (or the “" diagonal of) the confusion matrix:</p>
<ul>
<li>
<code>hi</code>: condition present (<code>TRUE</code>) &amp; decision positive (<code>TRUE</code>)</li>
<li>
<code>cr</code>: condition absent (<code>FALSE</code>) &amp; decision negative (<code>FALSE</code>)</li>
</ul>
</li>
<li>
<p>A decision is <em>incorrect</em> or <em>erroneous</em>, when it does not correspond to the condition. This also is the case for two cells in (or the “/” diagonal of) the confusion matrix:</p>
<ul>
<li>
<code>mi</code>: condition present (<code>TRUE</code>) &amp; decision negative (<code>FALSE</code>)</li>
<li>
<code>fa</code>: condition absent (<code>FALSE</code>) &amp; decision positive (<code>TRUE</code>)</li>
</ul>
</li>
</ul>
<p>Splitting all <code>N</code> individuals into two subgroups of those with correct vs. those with erroneous decisions yields a third perspective on the population:</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>by the correspondence of decisions to conditions (corresponding to the two diagonals of the confusion matrix):</li>
</ol>
<p><span class="math display">\[ 
\begin{aligned}
\texttt{N} \ &amp;= \ \texttt{dec_cor} &amp; +\ \ \ \ \ &amp;\texttt{dec_err}   &amp; \ \ \textrm{(c)}  \\
           \ &amp;= \ (\texttt{hi} + \texttt{cr}) &amp; +\ \ \ \ \ &amp;(\texttt{mi} + \texttt{fa}) \\
\end{aligned}
\]</span></p>
<div id="example-1" class="section level4">
<h4 class="hasAnchor">
<a href="#example-1" class="anchor"></a>Example</h4>
<p>Re-arranging the cells of the 2x2 confusion table allows illustrating accuracy as a 3rd perspective (e.g., by specifying the perspective <code>by = "cdac"</code>):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/plot_tab.html">plot_tab</a></span>(<span class="dt">prev =</span> .<span class="dv">05</span>, <span class="dt">sens =</span> .<span class="dv">75</span>, <span class="dt">spec =</span> .<span class="dv">66</span>, <span class="dt">N =</span> <span class="dv">1000</span>,
         <span class="dt">by =</span> <span class="st">"cdac"</span>, <span class="dt">p_split =</span> <span class="st">"h"</span>, 
         <span class="dt">p_lbl =</span> <span class="st">"def"</span>, <span class="dt">title_lbl =</span> <span class="st">"Scenario 2"</span>)</code></pre></div>
<div class="figure">
<img src="C_confusion_matrix_files/figure-html/plot_tab_cdac-1.png" alt="Arranging a 2x2 confusion table by condition and by accuracy." width="672"><p class="caption">
Arranging a 2x2 confusion table by condition and by accuracy.
</p>
</div>
<!-- (Note that the plot is not shown here, but please go ahead and generate it for yourself.) -->
</div>
<div id="avoiding-common-sources-of-confusion" class="section level4">
<h4 class="hasAnchor">
<a href="#avoiding-common-sources-of-confusion" class="anchor"></a>Avoiding common sources of confusion</h4>
<p>It may be instructive to point out two possible sources of confusion, so that they can be deliberately avoided:</p>
<ol style="list-style-type: decimal">
<li>
<p>Beware of alternative terms for <code>mi</code> and <code>cr</code>:</p>
<ul>
<li><p>Misses <code>mi</code> are often called “false negatives” (FN), but are nevertheless cases for which the condition is <code>TRUE</code> (i.e., in the <code>cond_true</code> column of the confusion table).</p></li>
<li><p>Correct rejections <code>cr</code> are often called “true negatives” (TN), but are nevertheless cases for which the condition is <code>FALSE</code> (i.e., in the <code>cond_false</code> column of the confusion table).</p></li>
</ul>
</li>
</ol>
<p>Thus, the terms “true” and “false” are sometimes ambiguous by switching their referents. When used to denote the four essential frequencies (e.g., describing <code>mi</code> as “false negatives” and <code>cr</code> as “true negatives”) the terms refer to the correspondence of a decision to the condition, rather than to their condition. To avoid this source of confusion, we prefer the terms <code>mi</code> and <code>cr</code> over “false negatives” (FN) and “true negatives” (TN), respectively, but offer both options as pre-defined lists of text labels (see <code>txt_org</code> and <code>txt_TF</code>).</p>
<ol start="2" style="list-style-type: decimal">
<li>Beware of alternative terms for <code>dec_cor</code> and <code>dec_err</code>:<br>
Similarly, it may be tempting to refer to instances of <code>dec_cor</code> and <code>dec_err</code> as “true decisions” and “false decisions”. However, this would also invite conceptual confusion, as “true decisions” would include <code>cond_false</code> cases (<code>cr</code> or TN cases) and “false decisions” would include <code>cond_true</code> cases (<code>mi</code> or FN cases). Again, we prefer the less ambiguous terms “correct decisions” vs. “erroneous decisions”.</li>
</ol>
</div>
</div>
</div>
<div id="accuracy-metrics" class="section level2">
<h2 class="hasAnchor">
<a href="#accuracy-metrics" class="anchor"></a>Accuracy metrics</h2>
<p>The perspective of accuracy raises an important question: How good is some decision process (e.g., a clinical judgment or some diagnostic test) in capturing the true state of the condition? Different accuracy metrics provide different answers to this question, but share a common goal — measuring decision performance by capturing the correspondence of decisions to conditions in some quantitative fashion.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<p>While all accuracy metrics quantify the relationship between correct and erroneous decisions, different metrics emphasize different aspects or serve different purposes. We distinguish between specific and general metrics.</p>
<div id="a--specific-metrics-conditional-probabilities" class="section level3">
<h3 class="hasAnchor">
<a href="#a--specific-metrics-conditional-probabilities" class="anchor"></a>A. Specific metrics: Conditional probabilities</h3>
<p>The goal of a specific accuracy metric is to quantify some particular aspect of decision performance. For instance, how accurate is our decision or diagnostic test in correctly detecting <code>cond_true</code> cases? How accurate is it in detecting <code>cond_false</code> cases?</p>
<p>As we are dealing with two types of correct decisions (<code>hi</code> and <code>cr</code>) and two perspectives (by columns vs. by rows), we can provide 4 answers to these questions. To obtain a numeric quantity, we divide the frequency of correct cases (either <code>hi</code> or <code>cr</code>) by</p>
<ol style="list-style-type: lower-alpha">
<li>column sums (<code>cond_true</code> vs. <code>cond_false</code>): This yields the decision’s <em>sensitivity</em> (<code>sens</code>) and <em>specificity</em> (<code>spec</code>):</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\texttt{sens} \ &amp;= \frac{\texttt{hi}}{\texttt{cond_true}} &amp; \ \ \textrm{(a1)}   \\
\ \\ 
\texttt{spec} \ &amp;= \frac{\texttt{cr}}{\texttt{cond_false}} &amp; \ \ \textrm{(a2)}  \\
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>row sums (<code>dec_pos</code> vs. <code>dec_neg</code>): This yields the decision’s <em>positive predictive value</em> (<code>PPV</code>) and <em>negative predictive value</em> (<code>NPV</code>):</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\texttt{PPV} \ &amp;= \frac{\texttt{hi}}{\texttt{dec_pos}} &amp; \ \ \ \textrm{(b1)}   \\
\ \\ 
\texttt{NPV} \ &amp;= \frac{\texttt{cr}}{\texttt{dec_neg}} &amp; \ \ \ \textrm{(b2)}   \\
\end{aligned}
\]</span></p>
</div>
<div id="b--general-metrics-measures-of-accuracy" class="section level3">
<h3 class="hasAnchor">
<a href="#b--general-metrics-measures-of-accuracy" class="anchor"></a>B. General metrics: Measures of accuracy</h3>
<p>In contrast to these specific metrics, general metrics of accuracy aim to capture overall performance (i.e., summarize the four essential frequencies of the confusion matrix) in a single quantity. <code>riskyr</code> currently computes four general metrics (which are contained in <code>accu</code>):</p>
<div id="overall-accuracy-acc" class="section level4">
<h4 class="hasAnchor">
<a href="#overall-accuracy-acc" class="anchor"></a>1. Overall accuracy <code>acc</code>
</h4>
<p>Overall accuracy (<code>acc</code>) divides the number of correct decisions (i.e., all <code>dec_cor</code> cases or the “" diagonal of the confusion table) by the number <code>N</code> of all decisions (or individuals for which decisions have been made). Thus,</p>
<blockquote>
<p>Accuracy <code>acc</code> := Proportion or percentage of cases correctly classified.</p>
</blockquote>
<p>Numerically, overall accuracy <code>acc</code> is computed as:</p>
<p><span class="math display">\[
\begin{aligned}
\texttt{acc} &amp;= \frac{\texttt{hi} + \texttt{cr}}{\texttt{hi} + \texttt{mi} + \texttt{fa} + \texttt{cr}} 
             = \frac{\texttt{dec_cor}}{\texttt{dec_cor} + \texttt{dec_err}} = \frac{\texttt{dec_cor}}{\texttt{N}}  
\end{aligned}
\]</span></p>
</div>
<div id="weighted-accuracy-wacc" class="section level4">
<h4 class="hasAnchor">
<a href="#weighted-accuracy-wacc" class="anchor"></a>2. Weighted accuracy <code>wacc</code>
</h4>
<p>Whereas overall accuracy (<code>acc</code>) does not discriminate between different types of correct and incorrect cases, weighted accuracy (<code>wacc</code>) allows for taking into account the importance of errors. Essentially, <code>wacc</code> combines the sensitivity (<code>sens</code>) and specificity (<code>spec</code>), but multiplies <code>sens</code> by a weighting parameter <code>w</code> (ranging from 0 to 1) and <code>spec</code> by its complement <code>(1 - w)</code>:</p>
<blockquote>
<p>Weighted accuracy <code>wacc</code> := the average of sensitivity (<code>sens</code>) weighted by <code>w</code>, and specificity (<code>spec</code>), weighted by <code>(1 - w)</code>.</p>
</blockquote>
<p><span class="math display">\[
\begin{aligned}
\texttt{wacc} \ &amp;= \texttt{w} \cdot \texttt{sens} \ + \ (1 - \texttt{w}) \cdot \texttt{spec} \\ 
\end{aligned}
\]</span></p>
<p>Three cases can be distinguished, based on the value of the weighting parameter <code>w</code>:</p>
<ol style="list-style-type: decimal">
<li><p>If <code>w = .5</code>, <code>sens</code> and <code>spec</code> are weighted equally and <code>wacc</code> becomes <em>balanced</em> accuracy <code>bacc</code>.</p></li>
<li><p>If <code>0 &lt;= w &lt; .5</code>, <code>sens</code> is less important than <code>spec</code> (i.e., instances of <code>fa</code> are considered more serious errors than instances of <code>mi</code>).</p></li>
<li><p>If <code>.5 &lt; w &lt;= 1</code>, <code>sens</code> is more important than <code>spec</code> (i.e., instances of <code>mi</code> are considered more serious errors than instances of <code>fa</code>).</p></li>
</ol>
</div>
<div id="matthews-correlation-coefficient-mcc" class="section level4">
<h4 class="hasAnchor">
<a href="#matthews-correlation-coefficient-mcc" class="anchor"></a>3. Matthews correlation coefficient <code>mcc</code>
</h4>
<p>The Matthews correlation coefficient (with values ranging from <span class="math inline">\(-1\)</span> to <span class="math inline">\(+1\)</span>) is computed as:</p>
<p><span class="math display">\[
\begin{aligned}
\texttt{mcc} \ &amp;= \frac{(\texttt{hi} \cdot \texttt{cr}) \ - \ (\texttt{fa} \cdot \texttt{mi})}{\sqrt{(\texttt{hi} + \texttt{fa}) \cdot (\texttt{hi} + \texttt{mi}) \cdot (\texttt{cr} + \texttt{fa}) \cdot (\texttt{cr} + \texttt{mi})}}  \\
\end{aligned}
\]</span></p>
<p>The <code>mcc</code> is a correlation coefficient specifying the correspondence between the actual and the predicted binary categories. A value of <span class="math inline">\(0\)</span> represents chance performance, a value of <span class="math inline">\(+1\)</span> represents perfect performance, and a value of <span class="math inline">\(−1\)</span> indicates complete disagreement between truth and predictions.</p>
<p>See <a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Wikipedia: Matthews correlation coefficient</a> for details.</p>
</div>
<div id="f1-score" class="section level4">
<h4 class="hasAnchor">
<a href="#f1-score" class="anchor"></a>4. F1 score</h4>
<p>For creatures who cannot live with only three general measures of accuracy, <code>accu</code> also provides the <em>F1 score</em>, which is the harmonic mean of <code>PPV</code> (aka. <em>precision</em>) and <code>sens</code> (aka. <em>recall</em>):</p>
<p><span class="math display">\[
\begin{aligned}
\texttt{f1s} \ &amp;=  2 \cdot \frac{\texttt{PPV} \cdot \texttt{sens}}{\texttt{PPV} + \texttt{sens}}  \\
\end{aligned}
\]</span></p>
<p>See <a href="https://en.wikipedia.org/wiki/F1_score">Wikipedia: F1 score</a> for details.</p>
</div>
</div>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<ul>
<li>Phillips, N. D., Neth, H., Woike, J. K., &amp; Gaissmaier, W. (2017). FFTrees: A toolbox to create, visualize, and evaluate fast-and-frugal decision trees. <em>Judgment and Decision Making</em>, <em>12</em>, 344–368. [Available online: <a href="http://journal.sjdm.org/17/17217/jdm17217.pdf">pdf</a> | <a href="http://journal.sjdm.org/17/17217/jdm17217.html">html</a> | <a href="https://CRAN.R-project.org/package=FFTrees">R package</a> ]</li>
</ul>
<p>Links to related Wikipedia articles:</p>
<ul>
<li>
<a href="https://en.wikipedia.org/wiki/Confusion_matrix">Confusion matrix</a> (URL: <a href="https://en.wikipedia.org/wiki/Confusion_matrix" class="uri">https://en.wikipedia.org/wiki/Confusion_matrix</a>)</li>
<li><a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Matthews correlation coefficient</a></li>
<li><a href="https://en.wikipedia.org/wiki/F1_score">F1 score</a></li>
</ul>
<div id="resources" class="section level3">
<h3 class="hasAnchor">
<a href="#resources" class="anchor"></a>Resources</h3>
<p>The following resources and versions are currently available:</p>
<table class="table">
<colgroup>
<col width="32%">
<col width="26%">
<col width="41%">
</colgroup>
<thead><tr class="header">
<th align="left">Type:</th>
<th align="left">Version:</th>
<th align="left">URL:</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">A. <code>riskyr</code> (R package):</td>
<td align="left"><a href="https://CRAN.R-project.org/package=riskyr">Release version</a></td>
<td align="left"><a href="https://CRAN.R-project.org/package=riskyr" class="uri">https://CRAN.R-project.org/package=riskyr</a></td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left"><a href="https://github.com/hneth/riskyr">Development version</a></td>
<td align="left"><a href="https://github.com/hneth/riskyr" class="uri">https://github.com/hneth/riskyr</a></td>
</tr>
<tr class="odd">
<td align="left">B. <code>riskyrApp</code> (R Shiny code):</td>
<td align="left"><a href="http://riskyr.org">Online version</a></td>
<td align="left"><a href="http://riskyr.org" class="uri">http://riskyr.org</a></td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left"><a href="https://github.com/hneth/riskyrApp">Development version</a></td>
<td align="left"><a href="https://github.com/hneth/riskyrApp" class="uri">https://github.com/hneth/riskyrApp</a></td>
</tr>
<tr class="odd">
<td align="left">C. Online documentation:</td>
<td align="left"><a href="https://hneth.github.io/riskyr">Release version</a></td>
<td align="left"><a href="https://hneth.github.io/riskyr" class="uri">https://hneth.github.io/riskyr</a></td>
</tr>
<tr class="even">
<td align="left"> </td>
<td align="left"><a href="https://hneth.github.io/riskyr/dev">Development version</a></td>
<td align="left"><a href="https://hneth.github.io/riskyr/dev" class="uri">https://hneth.github.io/riskyr/dev</a></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="contact" class="section level2">
<h2 class="hasAnchor">
<a href="#contact" class="anchor"></a>Contact</h2>
<!-- uni.kn logo and link to SPDS: -->
<p><a href="https://www.spds.uni-konstanz.de/"> <img src="../inst/pix/uniKn_logo.png" alt="spds.uni.kn" style="width: 280px; float: right; border:15;"></a></p>
<p>We appreciate your feedback, comments, or questions.</p>
<ul>
<li><p>Please report any <code>riskyr</code>-related issues at <a href="https://github.com/hneth/riskyr/issues" class="uri">https://github.com/hneth/riskyr/issues</a>.</p></li>
<li><p>Contact us at <a href="mailto:contact.riskyr@gmail.com">contact.riskyr@gmail.com</a> with any comments, questions, or suggestions.</p></li>
</ul>
</div>
<div id="all-riskyr-vignettes" class="section level2">
<h2 class="hasAnchor">
<a href="#all-riskyr-vignettes" class="anchor"></a>All riskyr vignettes</h2>
<!-- riskyr logo: -->
<p><a href="https://github.com/hneth/riskyr"> <img src="../inst/pix/riskyr_cube.png" alt="riskyr" style="width: 125px; float: right; border:20;"></a></p>
<!-- Index of vignettes: -->
<table class="table">
<thead><tr class="header">
<th align="right">Nr.</th>
<th align="left">Vignette</th>
<th align="left">Content</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">A.</td>
<td align="left"><a href="A_user_guide.html">User guide</a></td>
<td align="left">Motivation and general instructions</td>
</tr>
<tr class="even">
<td align="right">B.</td>
<td align="left"><a href="B_data_formats.html">Data formats</a></td>
<td align="left">Data formats: Frequencies and probabilities</td>
</tr>
<tr class="odd">
<td align="right">C.</td>
<td align="left"><a href="C_confusion_matrix.html">Confusion matrix</a></td>
<td align="left">Confusion matrix and accuracy metrics</td>
</tr>
<tr class="even">
<td align="right">D.</td>
<td align="left"><a href="D_functional_perspectives.html">Functional perspectives</a></td>
<td align="left">Adopting functional perspectives</td>
</tr>
<tr class="odd">
<td align="right">E.</td>
<td align="left"><a href="E_riskyr_primer.html">Quick start primer</a></td>
<td align="left">Quick start primer</td>
</tr>
</tbody>
</table>
<!-- eof. -->
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>To split a group into subgroups, some criterion for classifying the individuals of the group has to be used. If a criterion is binary (i.e., assigns only two different values), its application yields two subgroups. In the present case, both an individual’s <em>condition</em> and the corresponding <em>decision</em> are binary criteria.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>It is convenient to think of accuracy metrics as <em>outcomes</em> of the confusion table. However, when designing tests or decision algorithms, accuracy measures also serve as inputs that are to be maximized by some process (see Phillips et al., 2017, for examples).<a href="#fnref2">↩</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#basics">Basics</a><ul class="nav nav-pills nav-stacked">
<li><a href="#adopting-2-perspectives-on-a-population">Adopting 2 perspectives on a population</a></li>
      <li><a href="#accuracy-as-a-3rd-perspective">Accuracy as a 3rd perspective</a></li>
      </ul>
</li>
      <li>
<a href="#accuracy-metrics">Accuracy metrics</a><ul class="nav nav-pills nav-stacked">
<li><a href="#a--specific-metrics-conditional-probabilities">A. Specific metrics: Conditional probabilities</a></li>
      <li><a href="#b--general-metrics-measures-of-accuracy">B. General metrics: Measures of accuracy</a></li>
      </ul>
</li>
      <li>
<a href="#references">References</a><ul class="nav nav-pills nav-stacked">
<li><a href="#resources">Resources</a></li>
      </ul>
</li>
      <li><a href="#contact">Contact</a></li>
      <li><a href="#all-riskyr-vignettes">All riskyr vignettes</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by <a href="https://www.spds.uni-konstanz.de/hans-neth">Hansjoerg Neth</a>, <a href="https://www.spds.uni-konstanz.de/felix-gaisbauer">Felix Gaisbauer</a>, <a href="https://www.spds.uni-konstanz.de/nico-gradwohl">Nico Gradwohl</a>, <a href="https://www.spds.uni-konstanz.de/prof-dr-wolfgang-gaissmaier">Wolfgang Gaissmaier</a>.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.3.0.</p>
</div>
      </footer>
</div>

  

  </body>
</html>
