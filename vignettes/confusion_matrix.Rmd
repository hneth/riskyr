---
title: "Confusion Matrix and Metrics"
author: "HansjÃ¶rg Neth, SPDS, uni.kn"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette: 
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{Confusion Matrix and Metrics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Behold the aptly named "confusion matrix":

|              | Condition |          |       |          |            
| ------:      |:----:|:----:|:------:|:----:|              
| **Decision** | present (`TRUE`):      | absent (`FALSE`):     |     Sum:  |  (b) by decision:      |  
| positive (`TRUE`):   | `hi`         | `fa`         | `dec.pos` | `PPV` = `hi`/`dec.pos` |
| negative (`FALSE`):  | `mi`         | `cr`         | `dec.neg` | `NPV` = `cr`/`dec.neg` |
|      Sum:    | `cond.true`  | `cond.false` |       `N` |                        |
| (a) by condition  | `sens` = `hi`/`cond.true` | `spec` = `cr`/`cond.false` | |       |

Ordinary people, but also medical experts and social scientists, inevitably struggle to understand the implications of this matrix. 
This is no surprise when considering explanatory attempts like the corresponding article on [Wikipedia](https://en.wikipedia.org/wiki/Confusion_matrix), which squeezes more than a dozen metrics out of four essential frequencies (`hi`, `mi`, `fa`, and `cr`). While each particular metric is quite simple, their abundance and inter-dependence can be overwhelming.

In the following, we try to disentangle the profusion of measures and summarize the parts of the confusion matrix that a risk-literate person really needs to know.


## Basics

In its most basic form, the confusion matrix looks like this:

|              | Condition | |
| ------:      |:----:|:----:|      
| **Decision** | present (`TRUE`): | absent (`FALSE`): | 
| positive (`TRUE`):     |  `hi`   |  `fa`    |
| negative (`FALSE`):    |  `mi`   |  `cr`    | 


### Adopting 2 perspectives on a population

Essentially, the confusion table views a population of `N` individuals from two different perspectives. Adopting a perspective means that we distinguish between individuals on the basis of some criterion. The two criteria used here are:

(a) each individual's _condition_, which can either be present (`TRUE`) or absent (`FALSE`), and  
(b) each individual's _decision_, which can either be `positive` (`TRUE`) or `negative` (`FALSE`).   

Numerically, the adoption of each of these two perspectives splits the population into two subgroups.^[To split a group into subgroups, some criterion for classifying the individuals of the group has to be used. If a criterion is binary (i.e., assigns only two different values), its application yields two subgroups. In the present case, both an individual's _condition_ and the corresponding _decision_ are binary criteria.] Applying two different splits of a population into two subgroups results in $2 \times 2 = 4$ cases, which form the core of the confusion matrix:

1. `hi` represents _hits_ (or true positives): condition present (`TRUE`) & decision positive (`TRUE`). 
2. `mi` represents _misses_ (or false negatives): condition present (`TRUE`) & decision negative (`FALSE`). 
3. `fa` represents _false alarms_ (or false positives): condition absent (`FALSE`) & decision positive (`TRUE`). 
4. `cr` represents _correct rejections_ (or true negatives): condition absent (`FALSE`) & decision negative (`FALSE`). 

Importantly, all frequencies required to understand and compute various metrics are combinations of these four frequencies --- which is why we refer to them as the four _essential_ frequencies (see the vignette on [Data formats](data_formats.html)). For instance, adding up the columns and rows of the matrix yields the frequencies of the two subgroups that result from adopting our two perspectives on the population `N` (or splitting `N` into subgroups by applying two binary criteria):

(a) by condition (corresponding to the two columns of the confusion matrix): 

$$ 
\begin{aligned}
\texttt{N} \ &= \ \texttt{cond.true} & +\ \ \ \ \ &\texttt{cond.false}   & \textrm{(a)}      \\
           \ &= \ (\texttt{hi} + \texttt{mi}) & +\ \ \ \ \ &(\texttt{fa} + \texttt{cr}) \\
\end{aligned}
$$ 

(b) by decision (corresponding to the two rows of the confusion matrix): 

$$ 
\begin{aligned}
\texttt{N} \ &= \ \texttt{dec.pos} & +\ \ \ \ \ &\texttt{dec.neg}   & \ \ \ \ \textrm{(b)}      \\
           \ &= \ (\texttt{hi} + \texttt{fa}) & +\ \ \ \ \ &(\texttt{mi} + \texttt{cr}) \\
\end{aligned}
$$ 

### Accuracy as a 3rd perspective

A third way of grouping the four essential frequencies results from asking the question: Which of the four essential frequencies are _correct_ decisions and which are _erroneous_ decisions? Crucially, this question about decision _accuracy_ can neither be answered by only considering each individual's condition (i.e., the columns of the matrix), nor can it be answered by only considering each individual's decision (i.e., the rows of the matrix). Instead, the question requires considering the _correspondence_ between condition and decision. Checking the correspondence between rows and columns for the four essential frequencies yields an important insight: The confusion matrix contains _two_ types of correct decisions and _two_ types of errors:

- A decision is _correct_, when it corresponds to the condition. This is the case for two cells in (or the "\" diagonal of) the confusion matrix:

    - `hi`: condition present (`TRUE`) & decision positive (`TRUE`)
    - `cr`: condition absent (`FALSE`) & decision negative (`FALSE`) 
    
- A decision is _incorrect_ or _erroneous_, when it does not correspond to the condition. This also is the case for two cells in (or the "/" diagonal of) the confusion matrix:

    - `mi`: condition present (`TRUE`) & decision negative (`FALSE`)
    - `fa`: condition absent (`FALSE`) & decision positive (`TRUE`)

Splitting all `N` individuals into two subgroups of those with correct vs. those with erroneous decisions yields a third perspective on the population: 

(c) by the correspondence of decisions to conditions (corresponding to the two diagonals of the confusion matrix): 

$$ 
\begin{aligned}
\texttt{N} \ &= \ \texttt{dec.cor} & +\ \ \ \ \ &\texttt{dec.err}   & \ \ \textrm{(c)}      \\
           \ &= \ (\texttt{hi} + \texttt{cr}) & +\ \ \ \ \ &(\texttt{mi} + \texttt{fa}) \\
\end{aligned}
$$ 

### Avoiding common sources of confusion

It may be instructive to point out two possible sources of confusion, so that they can be deliberately avoided:

1. Beware of alternative terms for `mi` and `cr`:  

    - Misses `mi` are often called "false negatives", but are nevertheless cases for which the condition is `TRUE` 
    (i.e., in the `cond.true` column of the confusion table).

    - Correct rejections `cr`are often called "true negatives", are nevertheless cases for which the condition is `FALSE` 
    (i.e., in the `cond.false` column of the confusion table).

Thus, the terms "true" and "false" are ambiguous by switching their referents. When used to denote the four essential frequencies (e.g., describing `mi` as "false negatives" and `cr` as "true negatives") the terms refer to the correspondence of a decision to the condition, rather than to their condition. To avoid this source of confusion, we prefer the terms `mi` and `cr`, rather than "false negatives" and "true negatives".


2. Beware of alternative terms for `dec.cor` and `dec.err`:  
Similarly, it may be tempting to refer to instances of `dec.cor` and `dec.err` as "true decisions" and "false decisions". However, this would also invite conceptual confusion, as "true decisions" would include `cond.false` cases (`cr`) and "false decisions" would include `cond.true` cases (`mi`). Again, we prefer the less ambiguous terms "correct decisions" vs. "erroneous decisions".


## Accuracy Metrics

The perspective of accuracy raises an important question: How good is a given decision (e.g., a clinical judgment or some diagnostic test) in capturing the true state of the condition? Different accuracy metrics provide different answers to this question, but share a common goal --- measuring decision performance by capturing the correspondence of decisions to conditions in a single quantity.^[It is convenient to think of accuracy metrics as _outcomes_ of the confusion table. However, when designing tests or decision algorithms, accuracy measures also serve as inputs that are to be maximized by some process (see Phillips et al., 2017, for examples).]

While all accuracy metrics quantify the relationship between correct and erroneous decisions, different metrics emphasize different aspects or have different purposes. 

`riskyr` currently uses three such metrics (which are contained in `accu`):


### 1. Accuracy `acc`

Accuracy divides the number of correct decisions (i.e., all `dec.cor` cases or the "\" diagonal of the confusion table) by the number `N` of all decisions (or individuals for which decisions have been made). Thus, 

> Accuracy `acc` := Proportion or percentage of cases correctly classified.

Mathematically, the accuracy `acc` can be computed as:

$$
\begin{aligned}
\texttt{acc} &= \frac{\texttt{hi} + \texttt{cr}}{\texttt{hi} + \texttt{mi} + \texttt{fa} + \texttt{cr}} 
             = \frac{\texttt{dec.cor}}{\texttt{dec.cor} + \texttt{dec.err}} = \frac{\texttt{dec.cor}}{\texttt{N}}  
\end{aligned}
$$

+++ here now +++


### 2. Weighted accuracy `wacc`

Weighted accuracy: Taking into account the importance of errors.

Weighted accuracy, as a weighted average of the sensitivity sens (aka. hit rate HR, TPR, power or recall) and the the specificity `spec` (aka. TNR) in which `sens` is multiplied by a weighting parameter `w` (ranging from 0 to 1) and `spec` is multiplied by the complement `(1 - w)`:

$$
\texttt{wacc} = \texttt{w} \cdot \texttt{sens} + (1 - \texttt{w}) \cdot \texttt{spec}
$$

If `w = .5`, `wacc` becomes balanced accuracy `bacc`.


### 3. Matthews correlation coefficient `mcc`

The Matthews correlation coefficient (with values ranging from $-1$ to $+1$):

$$
\texttt{mcc} = \frac{(\texttt{hi} \cdot \texttt{cr}) - (\texttt{fa} \cdot \texttt{mi})}{\sqrt{(\texttt{hi} + \texttt{fa}) \cdot (\texttt{hi} + \texttt{mi}) \cdot (\texttt{cr} + \texttt{fa}) \cdot (\texttt{cr} + \texttt{mi})}}
$$

See [Wikipedia: Matthews correlation coefficient](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient) for details. 


## References

- Phillips, N. D., Neth, H., Woike, J. K., & Gaissmaier, W. (2017). 
FFTrees: A toolbox to create, visualize, and evaluate fast-and-frugal decision trees. 
_Judgment and Decision Making_, _12_, 344--368. 
[ [pdf](http://journal.sjdm.org/17/17217/jdm17217.pdf) | [html](http://journal.sjdm.org/17/17217/jdm17217.html) | [R package](https://CRAN.R-project.org/package=FFTrees) ]


Links to Wikipedia articles:

- [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) (URL: https://en.wikipedia.org/wiki/Confusion_matrix)
- [Matthews correlation coefficient](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient)


## All `riskyr` Vignettes

- [User guide](user_guide.html)
- [Data formats](data_formats.html)
- [Confusion matrix](confusion_matrix.html)

<!-- eof. -->




# Template

Vignettes are long form documentation commonly included in packages. Because they are part of the distribution of the package, they need to be as compact as possible. The `html_vignette` output type provides a custom style sheet (and tweaks some options) to ensure that the resulting html is as small as possible. The `html_vignette` format:

- Never uses retina figures
- Has a smaller default figure size
- Uses a custom CSS stylesheet instead of the default Twitter Bootstrap style

## Vignette Info

Note the various macros within the `vignette` section of the metadata block above. These are required in order to instruct R how to build the vignette. Note that you should change the `title` field and the `\VignetteIndexEntry` to match the title of your vignette.

## Styles

The `html_vignette` template includes a basic CSS theme. To override this theme you can specify your own CSS in the document metadata as follows:

    output: 
      rmarkdown::html_vignette:
        css: mystyles.css

## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
