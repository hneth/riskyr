---
title: "Quick Start Primer"
author: "Nico Gradwohl & HansjÃ¶rg Neth, SPDS, uni.kn"
date: "2018 02 15"
output: 
  rmarkdown::html_vignette: 
    fig_caption: yes
vignette: > 
  %\VignetteIndexEntry{Quick Start Primer}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library("riskyr")  # loads the package
```

<!-- riskyr logo: -->  
<a href="https://github.com/hneth/riskyr">
<img src="../inst/pix/riskyr_cube.png" alt="riskyr" style="width: 125px; float: right; border:15;"/>
</a>
<!-- ![riskyr](../inst/pix/riskyr_cube.png) --> 
<!-- knitr::include_graphics("../inst/pix/riskyr_cube.png") -->

`riskyr` is a toolbox for rendering risk literacy more transparent. Its goal is to gain deeper insights into risk-related scenarios with a minimum of hassle and maximum of fun.

This page assumes that you just installed the package and are now eager to see what you can do with it. (See the [User guide](A_user_guide.html) for a more general introduction.)


## Getting Started 

How can you use `riskyr`?  Basically, there are two ways to get started:

1. Define your own `riskyr` scenario from risk-related information (typically provided in terms of probabilities).

2. Inspect one of `r length(scenarios) - 1` predefined `riskyr` scenarios to get a glimpse of what types of scenarios are possible. 

Either way, you will soon explore some specific scenario and uncover relationships between its parameters. Let's load the package (in case you haven't already done so):

```{r load_riskyr}
library("riskyr")  # loads the package
```

### Defining a 1st scenario  

Let's launch your `riskyr`-career by creating a ficticious risk scenario that we construct from scratch: 


#### Example scenario

<!-- Example: Testing for recidivism -->

> **Identifying reoffenders**
> 
> Imagine you are developing a test to predict if a jailed criminal offender will reoffend after his or her release. 
> Your research yields the following information: 
>
> 1. 45% of 753 jailed offenders in this county re-offend after they are released (`prev = .45`).  
> 2. Your test correctly detects those who will re-offend in 98% of the cases (`sens = .98`).  
> 3. Your test falsely identifies 54% of those who will not re-offend as potential re-offenders. 
> Conversely, this implies that your test correctly identifies 46% of those that will not reoffend (`spec = .46`).  
> 
> John D. is about to get released. However, your test predicts that he will reoffend.  
> 
> What is the probability that John D. will actually reoffend, given this test result? 

To answer this question, you could calculate corresponding probabilities or frequencies (as explained in the [user guide](A_user_guide.html)). Alternatively, you can use the `riskyr()` function to create a `riskyr` scenario that you can modify, inspect, and visualize in various ways.


#### Necessary scenario information

<!-- A: necessary info: probabilities and N: --> 

First, let's translate the numeric information provided in our example into parameter values:

1. The probability of reoffending provides the _prevalence_ in our population: `prev = .45`.  

2. The test's conditional probability of correctly detecting a reoffender provides its _sensitivity_: `sens = .98`.  

3. The test's conditional probability of correctly detecting someone who will not reoffend provides its _specificity_: `spec = .46`.  
(This corresponds to a _false alarm rate_ `fart = 1 - spec = .54`.)  

4. In addition, the _population size_ of your sample was mentioned to be `N = 753`.^[If no population size value `N` is specified, a suitable value is provided.]  


The following code defines a perfectly valid `riskyr` scenario:

```{r create_scenario_minimal}
# Create a minimal scenario:
my.scenario <- riskyr(prev = .45, 
                      sens = .98,
                      spec = .46)
```

<!-- Mention alternative ways of entering the same (e.g., by providing fart, rather than spec)? --> 


#### Optional scenario information

<!-- B: optional info: text labels --> 

To make various outputs more recognizable, many aspects of a `riskyr` scenario can be described by setting optional `arguments`: 

* `scen.lbl` specifies a label by which you can reckognize the scenario (e.g., "Identifying reoffenders").  
* `popu.lbl` specifies the population of interest (e.g., "inmates").  

* `cond.lbl` specifies the condition of interest (i.e., "reoffending").
* `cond.true.lbl` specifies a label for the condition being true ("offends again").
* `cond.false.lbl` specifies a label for the condition being false ("does not offend again").

* `dec.lbl` specifies the nature of the decision, prediction, or test ("test result").
* `dec.pos.lbl` specifies a positive decision regarding the condition ("predict to reoffend").
* `dec.neg.lbl` specifies a negative decision regarding the condition ("predict to not reoffend").

* `hi.lbl`, `mi.lbl`, `fa.lbl`, and `cr.lbl` specify the four possible combinations of conditions and decisions: 
    1. hit: The test predicts that the inmate reoffends and s/he does ("reoffender found");   
    2. miss: The test predicts that the inmate does not reoffend but s/he does ("reoffender missed");   
    3. false alarm: The test predicts that the inmate reoffends but s/he does not ("false accusation";   
    4. correct rejection: The test predicts that the inmate does not reoffend and s/he does not ("correct release").  

Whereas specifying three essential probabilities is necessary to define a valid `riskyr` scenario, providing `N` and the other arguments are entirely optional. Let's create a well-specified `riskyr` scenario:

```{r create_scenario_custom}
# Create a customized scenario: 
my.scenario <- riskyr(scen.lbl = "Identifying reoffenders", 
                      popu.lbl = "inmates", 
                      cond.lbl = "reoffending",
                      cond.true.lbl = "offends again", cond.false.lbl = "does not offend again",
                      dec.lbl = "test result",
                      dec.pos.lbl = "predict to\nreoffend", dec.neg.lbl = "predict to\nnot reoffend",
                      hi.lbl = "reoffender found", mi.lbl = "reoffender missed",
                      fa.lbl = "false accusation", cr.lbl = "correct release",
                      prev = .45,  # prevalence of being a reoffender. 
                      sens = .98,  # p( will reoffend | offends again )
                      spec = .46,  # p( will not reoffend | does not offend again )
                      fart =  NA,  # p( will reoffend | does not offend gain )
                      N = 753,     # population size
                      scen.src = "(a ficticious example)")
```


#### Viewing scenario information

We _could_ inspect the details of `my.scenario` with `summary(my.scenario)`. But it's much more colorful to immediately check some visualizations of our scenario:

```{r fnet, include = FALSE, fig.width = 7.2, fig.height = 6}
plot(my.scenario, plot.type = "fnet", round = FALSE)
```

An icon array displays the entire population of inmates classified by condition (whether they will reoffend or not) and decisions (our test's predictions). We can plot this display for our scenario by using the `plot` function and specifying the `plot.type = "icons"`:

```{r icons, fig.width = 7.2, fig.height = 4.8}
plot(my.scenario, plot.type = "icons")
```

From the icon array, We can easily see that roughly half of the inmates reoffend (see the icons in dark green and dark red). The majority of the reoffenders are classified correctly (shown in dark green rather than dark red). 

But where is John D.? His test result predicted that he would reoffend. Depending on his actual behavior, this means that he will _either_ be classified as a "reoffender found" (if he actually reoffends: dark green icons) _or_ as a "false accusation" (if he does not reoffend: light red icons). As there are a similar number of both types of icons (with some skew towards "reoffenders found"), it appears that his chances of actually reoffending are only slighly higher than chance.

To dig into the dirty details of `my.scenario`, let's look at its `summary`:

```{r full_summary}
summary(my.scenario)
```

The text output (printed in R's console window) provides a brief description of our scenario (i.e., its name, the condition and decision of interest, as well as the type and size of population), followed by a range of numeric parameters (structured into probabilities, frequencies, and overall accuracy). 

In the present case, we were interested in a person's conditional probability of reoffending given a positive test result. This metric is also known as the _positive predictive value_ (PPV). Our summary information shows `PPV = 0.598`. Thus, based on the information provided, John D.'s probability of reoffending is 59.8\% (quite in line with our visual estimate from the icon array above). 


```{r summary_prob, include = FALSE}
summary(my.scenario, summarize = "prob")
```


#### Alternative perspectives

An alternative way to view the our scenario is a frequency tree that splits the population into two subgroups (e.g., by the two possible results of our test) and then classify all members of the population by the possible combinations of decision and actual condition, yielding the same four types of frequencies as identified above (and listed as `hi`, `mi`, `fa`, and `cr` in the `summary` above): 

```{r tree, fig.width = 7.2, fig.height = 5.5}
plot(my.scenario, plot.type = "tree", by = "dc")  # plot tree diagram (splitting N by decision)
```

The frequency tree also shows us how the PPV (shown on the arrow on the lower left) can be computed from 
frequencies (shown in the boxes): PPV = (number of offenders found)/(number of people predicted to reoffend) (or `PPV = hi/dec.pos`). Numerically, we see that `PPV = 332/556`, which amounts to about 60\% (or `1 - 0.403`). 

The tree also depicts additional information that corresponds to our `summary` from above. For instance, if we had wondered about the negative predictive value (NPV) of a negative test result (i.e., the conditional probability of not offending given that the test predicted this), the tree shows this to be `NPV = 190/197` or about 96.4\% (as `NPV = cr/dec.neg`). Again, this closely corresponds to our `summary` information of `NPV = 0.966`.^[The difference between `NPV = 190/197 = 0.964467` (when computing the ratio of frequencies) and `NPV = 0.966` (in the `summary`) is due to rounding tree frequencies to integer values. If absolute precision is required, we can plot the frequency tree without rounding by adding an argument `round = FALSE`.]  

A good question to ask is: To what extend do the positive and negative predictive values (PPV and NPV) depend on the likelihood of reoffending in our population (i.e., the condition's prevalence)? To answer this, the following code allows to show conditional probabilities (here `PPV` and `NPV`) as a function of `prev`: 

```{r plotting_curve, fig.width=7, fig.height=5.5}
plot(my.scenario, plot.type = "curve")
```

As before, we can read off that the current values of `PPV = 59.76%` and `NPV = 96,56%`. Importantly, the curves also show that the prevalence value is absolutely crucial for the value of both `PPV` and `NPV`. For instance, if `prev` dropped further, the `PPV` of our test was also considerably lower. In fact, both the PPV and NPV vary from 0 to 1 depending on the value of `prev`, which means that specifying them is actually meaningless when the corresponding value of `prev` is not communicated as well. (See the guide on [functional perspectives](D_functional_perspectives.html) for additional information and options.) 

Having illustrated how we can create a scenario from scratch and begin to inspect it in a few ways, we can now turn towards loading scenarios that are contained in the `riskyr` package.


### Using existing scenarios

As defining your own scenarios can be cumbersome and the literature is full of existing problems (that study so-called Bayesian reasoning), `riskyr` provides a set of -- currently `r length(scenarios) - 1`) -- pre-defined scenarios (stored in a list `scenarios`). The following table provides a first overview of the scenarios avaliable, including their relevant condition, their population size `N`, and basic probability information: 

```{r scenario_table, echo = FALSE, results = 'asis'}
library(knitr)
scen.table <- df.scenarios[-1,
                           c("scen.lbl", "cond.lbl", "N", "prev",
                             "sens", "spec", "fart")]
scen.table[, -c(1:2)] <- round(scen.table[, -c(1:2)], 3)
names(scen.table) <- c("Scenario", "Condition", "N", "prev", "sens", "spec", "fart")
kable(scen.table)
```


Here is how you can explore them:

#### 1. Selecting a scenario

To select a particular scenario, assign it to an R object. For instance, let's assign Scenario 21 to `s21`:

```{r s21_select}
s21 <- scenarios$n21  # assign pre-defined Scenario_21 to s21
```

#### 2. Printing scenario information

As each scenario is stored as a list, different aspects of a scenario can be printed by their element names:

```{r s21_info}
# Show scenario information: 
s21$scen.lbl  # shows descriptive label:
s21$cond.lbl  # shows current condition:
s21$popu.lbl  # shows current population:
s21$prev      # shows the current prevalence
s21$scen.src  # shows current source: 
```

A description of the scenario can be printed by calling `s21$scen.txt`: 

    `r scenarios$n21$scen.txt`

As explained above, an overview of the main parameters of a scenario is provided by `summary`: 

```{r s21_summary}
summary(s21) # shows all scenario information.
```

Note that -- in this particular population -- the prevalence for the condition (`r s21$cond.lbl`) is assumed to be relatively high (with a value of `r as_pc(s21$prev)`%).


#### 3. Visualizing scenarios

To eyeball key scenario information, we could inspect an icon array as follows: 

```{r s21_icons, fig.width = 7.2, fig.height = 4.5}
plot(s21, plot.type = "icons", cex.lbl = 0.75)
```

Given that green squares signal correct classifications and red squares signal incorrect classifications, it is immediately obvious that our main accuracy issue here is with so-called misses: Men with cancer that remain undetected (printed in dark red).

To further illuminate the scenario, consider the following network diagram: 

```{r s21_fnet, fig.width = 7.2, fig.height = 6.5}
plot(s21, plot.type = "fnet", area = "sq")
```


+++ here now +++: 


```{r s21_curve, fig.width = 7, fig.height = 5}
plot(s21, plot.type = "curve", what = "all")
```


### Exercise

Contrast this with Scenario 22: 

    `r scenarios$n22$scen.txt` 

```{r s22_summary}
s22 <- scenarios$n22  # assign pre-defined Scenario_22 to s22. 

summary(s22)
```


We see that the prevalence in scenario 22 is way lower than in scenario 21.  Besides this, they are equivalent, i.e., they use the same test. 

But how does this affect the value of the test?  

```{r example_use_b, fig.width=7.5, fig.height=5.5}
op <- par(no.readonly = TRUE)
par(mfrow = c(1,2))  # set plotting space for direct comparison. 

## Contrast two versions: 
plot(s21, plot.type = "plane", what = "PPV", cex.lbl = 0.75)
plot(s22, plot.type = "plane", what = "PPV", cex.lbl = 0.75)
```

Firstly, these planes clearly illustrate that with a high prevalence the positive predictive value is considerably higher than with a low prevalence.  Additionally, it can be seen that decreasing specificity and sensitivity in a scenario with high prevalence has a stronger impact.  In a scenario with low prevalence an increase in specificity , in turn, has a very strong impact, while there is not so much room for improvement with high prevalence. 

```{r examples_NPV, fig.width=7.5, fig.height=5.5}
op <- par(no.readonly = TRUE)
par(mfrow = c(1,2))  # set plotting space for direct comparison. 

## Contrast two versions: 
plot(s21, plot.type = "plane", what = "NPV", cex.lbl = 0.75)
plot(s22, plot.type = "plane", what = "NPV", cex.lbl = 0.75)
```

Apparently, for low prevalence things are vice versa. 

For further information see [User guide](A_user_guide.html). 

```{r reset_par, echo = FALSE}
par(op)
```


Now have fun exploring the provided examples, as well as creating and exploring your own examples. 


## All `riskyr` Vignettes

<!-- riskyr logo: -->
<a href="https://github.com/hneth/riskyr">
<img src="../inst/pix/riskyr_cube.png" alt="riskyr" style="width: 125px; float: right; border:10;"/>
</a>

<!-- Index of vignettes: -->

| Nr.  | Vignette | Content    |        
| ---: |:---------|:-----------|
| A. | [User guide](A_user_guide.html) | Motivation and general instructions | 
| B. | [Data formats](B_data_formats.html) | Data formats: Frequencies and probabilities | 
| C. | [Confusion matrix](C_confusion_matrix.html) | Confusion matrix and accuracy metrics |
| D. | [Functional perspectives](D_functional_perspectives.html) | Adopting functional perspectives |
| E. | [Quick start primer](E_riskyr_primer.html) | Quick start primer |

<!-- eof. -->
