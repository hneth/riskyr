---
title: "A `riskyr` Primer"
author: "Nico Gradwohl & Hansjörg Neth, SPDS, uni.kn"
date: "2018 02 14"
output: 
  rmarkdown::html_vignette: 
    fig_caption: yes
vignette: > 
  %\VignetteIndexEntry{User Guide}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

`riskyr` is a toolbox for rendering risk literacy more transparent by facilitating changes in representation and offering multiple perspectives on the dynamic interplay between probabilities and frequencies. 

The main goal of `riskyr` is to provide a long-term boost in risk literacy by fostering competence in understanding statistical information in domains such as health, weather, and finances (Hertwig & Grüne-Yanoff, 2017).


## Getting Started 

How can you use `riskyr`?  Basically, there are two ways to get started:

1. Define your own `riskyr` scenario from risk-related information.

2. Use one of `r length(scenarios) - 1` predefined scenarios to get a glimpse of what types of scenarios can be explored with `riskyr`. 


### Defining your own scenario  

Let's launch your `riskyr`-career by creating a ficticious risk scenario that we can construct from scratch. 

<!-- Example: Testing for recidivism -->

> **Identifying reoffenders**
> 
> Imagine you are developing a test for criminal offenders in jail. 

> 1. You know that 45% of all 753 offenders in this particular jail re-offend after they are released (`prev = .45`).  
> 2. You developed a test that correctly identifies those who will re-offend in 98% of the cases (`sens = .98`).  
> 3. The test also falsely identifies 64% of those who will not re-offend as potential re-offenders or conversely, correctly identifies 46% of those that will not reoffend (`spec = .46`).  
> 
> John D. is about to get released.  However, your test result suggests that he will likely reoffend.  
> 
> What is the probability that John D. will actually reoffend, given this test result? 


To answer this question you can use Bayes formula or natural frequencies (as explained in the [user guide](A_user_guide.html)). Alternatively, you can use the `riskyr()` function to create a scenario (as a `riskyr` object) that you can modify, inspect, and visualize in many different ways. 

A new scenario can be described in many different ways: 

* `scen.lbl` A telling name (e.g., "Identifying reoffenders").  

* `popu.lbl` specifies the population of interest (e.g., "inmates").

* `cond.lbl` A label for the condition of interest (i.e., "reoffending").
* `cond.true.lbl` specifies a label for the condition being true ("offends again").
* `cond.false.lbl` specifies a label for the condition being false ("does not offend again").

* `dec.lbl` specifies the nature of the decision, prediction, or test ("test result").
* `dec.pos.lbl` specifies a positive decision relative to the condition ("predict to reoffend").
* `dec.neg.lbl` specifies a negative decision relative to the condition ("predict to not reoffend").

* The labels `hi.lbl`, `mi.lbl`, `fa.lbl`, and `cr.lbl` specify the four possible combinations of condition and decisions: 
    * "reoffender found" (hit: the test predicts that the inmate reoffends and s/he does), 
    * "reoffender missed" (miss: the test predicts that the inmate does not reoffend but s/he does), 
    * "false accusation" (false alarm: the test predicts that the inmate reoffends but s/he does not), and 
    * "correct release" (correct rejection: the test predicts that the inmate does not reoffend and s/he does not). 
    
    
Crucially, you should specify the available numeric information on the population and the test: 

1. `prev` the _prevalence_ or how many inmates reoffend at all. 
2. `sens` the _sensitivity_ or how many reoffenders are correctly classified by the test. 
3. `spec` the _specificity _ or how many non reoffenders are correctly identified. 

4. `N` the _population size_ or how many inmates are there in prison. 

Let us create a custom `riskyr` object: 

```{r create_scenario}
# Create a custom scenario: 
my.scenario <- riskyr(scen.lbl = "Identifying reoffenders", 
                      popu.lbl = "inmates", 
                      cond.lbl = "reoffending",
                      cond.true.lbl = "offends again", cond.false.lbl = "does not offend again",
                      dec.lbl = "test result",
                      dec.pos.lbl = "predict to reoffend", dec.neg.lbl = "predict to not reoffend",
                      hi.lbl = "reoffender found", mi.lbl = "reoffender missed",
                      fa.lbl = "false accusation", cr.lbl = "correct release",
                      prev = .45,  # prevalence of being a reoffender. 
                      sens = .98,  # p( will reoffend | offends again )
                      spec = .46,  # p( will not reoffend | does not offend again )
                      fart =  NA,  # p( will reoffend | does not offend gain )
                      N = 753,     # population size
                      scen.src = "ficticious example scenario")
```


First, we can visualize our new object in different ways: 

The iconarray displays the whole population of inmates and how they are classified and whether they will reoffend.  We can do this with a simple call to `plot()` using the `plot.riskyr()` method with `plot.type = "icons"`:

```{r icons, fig.width=7, fig.height=5}
plot(my.scenario, plot.type = "icons", cex.lbl = 0.85)
```

We can relatively easily see that roughly half of the inmates reoffend (dark green and dark red icons).  Of those most are classified corretly.  But what about John D.?  His test result suggeested that he would reoffend.  How likely will he actually reoffend? 

Therefore we need to consider the dark green icons (hits, the test suggests that someone reoffends and the person actually does) and the light red icons (false alarms, the test suggests that these will reoffend but they actually don't).  We see that this is roughly half with an advantage for hits.  


Now we can use the `summary` function to confirm this: 

```{r full_summary}
summary(my.scenario)
```

From there we can read off some specifics of our scenario like the name, the condition of interest, what our decision is based on (the test), and how many individuals are there.  Moreover, we can read out probabilities, frequencies, and overall accuracy.  This contains much information we actually don't need to answer our question.   So we might want to limit this to the probabilities, as we are interested in the probability of reoffending, given a positive test result, the _positive predictive value_ or `PPV`. 

```{r summary_prob}
summary(my.scenario, summarize = "prob")
```

Reading off `PPV` from the table we can see that the rough intuition was almost correct with about 60% with a positive test result actually reoffending. 

We may even visualize this using a frequency tree: 

```{r tree, fig.width=7, fig.height=6}
plot(my.scenario, plot.type = "tree", by = "dc")
```

We find again the PPV here.  From its complement (.403) we can infer that it is around 60%.  

We can also infer additional information.  For instance, those that get a negative test result (i.e., the test suggests that they will not reoffend) will likely actually not reoffend.  The NPV (infered from the complement; see also the summary above) suggests that this holds in around 97% of all cases. 

A final way of visualizing this are curves which are dependent on prevalence. 

```{r plotting_curve, fig.width=7, fig.height=5.5}
plot(my.scenario, plot.type = "curve")
```

Here we see again our PPV of around 60% and the NPV of around 97%.  We can see that if prevalence dropped or was actually lower than 45%, the informativeness of a positve test result about reoffending would drop considerably.  

This illustrated, how you can create a scenario from risk information and visualize it with `riskyr`. 

For further information on underlying principles and additional functionalities see [User guide](A_user_guide.html). 


### Using existing scenarios

As defining your own scenarios can be cumbersome and the literature is full of similar problems (of so-called Bayesian reasoning), `riskyr` provides a set of (currently 25) pre-defined scenarios (stored in a list `scenarios`). 

Here is a table of all scenarios avaliable, including some information on the relevant condition and decision, as well as the probabilities (for additional information see `scen.txt`):  

```{r scenario_table, echo = FALSE, results = 'asis'}
library(knitr)
scen.table <- df.scenarios[-1,
                           c("scen.lbl", "cond.lbl", "dec.lbl", "N", "prev",
                             "sens", "spec", "fart", "scen.src")]
scen.table[, -c(1:3, 9)] <- round(scen.table[, -c(1:3, 9)], 3)
names(scen.table) <- c("Scenario", "Condition", "Decision",
                       "N", "Prevalence", "Sensitivity", "Specificity", "False alarm rate",
                       "Source")
kable(scen.table)
```


Show (some columns of) `scenarios` as table?

Here is how you can explore them: 

Let us consider the scenarios number 21 and 22.  Strating with scneraio number 21:  

    `r scenarios$n21$scen.txt`

```{r example_use_a, fig.width=7, fig.height=5.5}
## (a) PSA screening with high prevalence: ----------
s21 <- scenarios$n21  # assign pre-defined Scenario_21 to s
```

First, we summarize all of the information: 

```{r summary_s21}
summary(s21) # shows all scenario information.
```

If we are only interested in frequencies, we can look at these: 

```{r summary_s21_freq}
summary(s21, summarize = "freq") # shows frequencies. 
```

Now we can consider a few graphics: 

```{r s21_net, fig.width=7, fig.height=6}
plot(s21) # plots a network diagram (by default)
```


```{r s21_icons, fig.width = 7, fig.height = 5}
plot(s21, plot.type = "icons", cex.lbl = 0.75)
```

```{r s21_curve, fig.width = 7, fig.height = 5}
plot(s21, plot.type = "curve", what = "all")
```


Now we also consider scenario number 22: 

    `r scenarios$n22$scen.txt` 

```{r s22_summary}
s22 <- scenarios$n22  # assign pre-defined Scenario_22 to s22. 

summary(s22)
```


We see that the prevalence in scenario 22 is way lower than in scenario 21.  Besides this, they are equivalent, i.e., they use the same test. 

But how does this affect the value of the test?  

```{r example_use_b, fig.width=7.5, fig.height=5.5}
op <- par(no.readonly = TRUE)
par(mfrow = c(1,2))  # set plotting space for direct comparison. 

## Contrast two versions: 
plot(s21, plot.type = "plane", what = "PPV", cex.lbl = 0.75)
plot(s22, plot.type = "plane", what = "PPV", cex.lbl = 0.75)

```

Firstly, these planes clearly illustrate that with a high prevalence the positive predictive value is considerably higher than with a low prevalence.  Additionally, it can be seen that decreasing specificity and sensitivity in a scenario with high prevalence has a stronger impact.  In a scenario with low prevalence an increase in specificity , in turn, has a very strong impact, while there is not so much room for improvement with high prevalence. 

```{r examples_NPV, fig.width=7.5, fig.height=5.5}
op <- par(no.readonly = TRUE)
par(mfrow = c(1,2))  # set plotting space for direct comparison. 

## Contrast two versions: 
plot(s21, plot.type = "plane", what = "NPV", cex.lbl = 0.75)
plot(s22, plot.type = "plane", what = "NPV", cex.lbl = 0.75)
```


Apparently, for low prevalence things are vice versa. 

For further information see [User guide](A_user_guide.html). 

```{r reset_par, echo = FALSE}
par(op)
```


Now have fun exploring the provided examples, as well as creating and exploring your own examples. 

## All `riskyr` Vignettes

<!-- riskyr logo: -->
<a href="https://github.com/hneth/riskyr">
<img src="../inst/pix/riskyr_cube.png" alt="riskyr" style="width: 125px; float: right; border:10;"/>
</a>

<!-- Index of vignettes: -->

| Nr.  | Vignette | Content    |        
| ---: |:---------|:-----------|
| A. | [User guide](A_user_guide.html) | Motivation and general instructions | 
| B. | [Data formats](B_data_formats.html) | Data formats: Frequencies and probabilities | 
| C. | [Confusion matrix](C_confusion_matrix.html) | Confusion matrix and accuracy metrics |
| D. | [Functional perspectives](D_functional_perspectives.html) | Adopting functional perspectives |
| E. | [A `riskyr` primer](E_riskyr_primer.html) | A primer to get started with `riskyr` |

<!-- eof. -->
